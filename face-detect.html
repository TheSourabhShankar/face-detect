<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>Face Detection using tracking.js</title>
  <script src="build/tracking-min.js"></script>
  <script src="build/data/face-min.js"></script>
  <script src="build/data/eye-min.js"></script>
  <script src="build/data/mouth-min.js"></script>
  <style>
    video, canvas {
      position: absolute;
    }

    .demo-container {
      position: relative;
      width:75%;
      margin:0 auto;
    }

    .left,.right {
      position: relative;
      display: block;
      float:left;
      width:50%;
    }
    .right {
      position: relative;
      display: block;
      float:right;
      width:50%;
    }
    
    #noFace,#gotFace {
      position: absolute;
      top:0px;
      left:0px;
      transition: opacity 0.5 
      -webkit-transition: opacity 0.5s; /* Safari */
      transition: opacity 0.5s;
    }

    #noFace {
      opacity:1;
    }

    #gotFace {
      opacity:0;
    }

    .chat {
      font-size:20px;
    }
  </style>
</head>
<body>
    <div class="demo-container">
      <div class="left">
        <video id="video" width="480" height="320" preload autoplay loop muted></video>
        <canvas id="canvas" width="480" height="320"></canvas>
      </div>
      <div class="right">
        <div id="noFace">
          <span class="chat">Hey, where you going?</span>
          <br>
          <img src="assets/sad.png" id="img" width="200" />
        </div>
        <div id="gotFace">
          <span class="chat">Yeah, you are finally here</span>
          <br>
          <img src="assets/happy.png" id="img" width="200" />
        </div>
      </div>
    </div>
    <button type="button" onclick="stopStreamedVideo(document.getElementById('video'));">Stop Camera</button>
  <script>
    //get instances of video, canvas
    var video = document.getElementById('video');
    var canvas = document.getElementById('canvas');
    var context = canvas.getContext('2d');

    //used for updating smiley divs
    var gotFaceDiv = document.getElementById('gotFace');
    var noFaceDiv = document.getElementById('noFace');
    var gotFace = false;

    window.onload = function() {
      //decide that body parts to detect
      var tracker = new tracking.ObjectTracker(['face']); //['face','eye','mouth']
      tracker.setInitialScale(4);
      tracker.setStepSize(2);
      tracker.setEdgesDensity(0.1);
      
      //tracking camera stream
      tracking.track('#video',tracker,{camera:true});

      //track event fire continuously on camera stream
      tracker.on('track',function(event){
        context.clearRect(0, 0, canvas.width, canvas.height);
        if (event.data.length === 0) {
          //no face detected
          gotFace = false;
        } 
        else {
          //face detected
          gotFace = true;
          //create a box around face
          event.data.forEach(function(rect) {
            context.strokeStyle = '#ff0000';
            context.strokeRect(rect.x, rect.y, rect.width, rect.height);
            context.font = '11px Helvetica';
            context.fillStyle = "#fff";
            context.fillText('x: ' + rect.x + 'px', rect.x + rect.width + 5, rect.y + 11);
            context.fillText('y: ' + rect.y + 'px', rect.x + rect.width + 5, rect.y + 22);
          });
        }
        updateChat(gotFace);
      });
      //var interval = setInterval(updateChat(gotFace), 3000);
    };
    //update text and image based on where face is detected or not
    function updateChat(face,id){
      //change opacity of divs
      if(face)
      {
        console.log('gotFace');
        noFaceDiv.style.opacity = 0;
        gotFaceDiv.style.opacity = 1;
      }
      else{
        console.log('noFace'); 
        gotFaceDiv.style.opacity = 0;
        noFaceDiv.style.opacity = 1;
      }
    }
    function stopStreamedVideo(videoElem) {
      let stream = videoElem.srcObject;
      let tracks = stream.getTracks();

      tracks.forEach(function(track) {
        track.stop();
      });

      videoElem.srcObject = null;
    }
  </script>
</body>
</html>
